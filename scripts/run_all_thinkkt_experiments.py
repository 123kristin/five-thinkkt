#!/usr/bin/env python
"""
æ‰¹é‡è¿è¡ŒThinkKTæ¨¡å‹çš„æ‰€æœ‰å®éªŒç»„åˆ
åŒ…æ‹¬ï¼š3ä¸ªæ•°æ®é›† Ã— 2ç§åºåˆ—æ¨¡å‹ç±»å‹ Ã— 3ç§å±‚æ•° = 18ä¸ªå®éªŒ
"""
import os
import sys
import subprocess
import argparse
from datetime import datetime
from pathlib import Path
from multiprocessing import Pool, Manager
import time

# æ·»åŠ è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '../scripts_training2testing/examples'))

def run_command(cmd, description, log_file=None):
    """
    è¿è¡Œå‘½ä»¤å¹¶è®°å½•æ—¥å¿—
    
    Args:
        cmd: å‘½ä»¤åˆ—è¡¨
        description: å‘½ä»¤æè¿°
        log_file: æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
    """
    print("=" * 80)
    print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {description}")
    print("=" * 80)
    print(f"æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
    print("-" * 80)
    
    if log_file:
        with open(log_file, 'a', encoding='utf-8') as f:
            f.write(f"\n{'='*80}\n")
            f.write(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {description}\n")
            f.write(f"{'='*80}\n")
            f.write(f"æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}\n")
            f.write(f"{'-'*80}\n")
            f.flush()
    
    try:
        # è¿è¡Œå‘½ä»¤ï¼Œå®æ—¶è¾“å‡º
        process = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            universal_newlines=True,
            bufsize=1
        )
        
        # å®æ—¶æ‰“å°è¾“å‡º
        for line in process.stdout:
            print(line, end='')
            if log_file:
                with open(log_file, 'a', encoding='utf-8') as f:
                    f.write(line)
                    f.flush()
        
        process.wait()
        return_code = process.returncode
        
        if return_code != 0:
            print(f"\nâŒ å‘½ä»¤æ‰§è¡Œå¤±è´¥ï¼Œè¿”å›ç : {return_code}")
            if log_file:
                with open(log_file, 'a', encoding='utf-8') as f:
                    f.write(f"\nâŒ å‘½ä»¤æ‰§è¡Œå¤±è´¥ï¼Œè¿”å›ç : {return_code}\n")
            return False
        else:
            print(f"\nâœ… å‘½ä»¤æ‰§è¡ŒæˆåŠŸ")
            if log_file:
                with open(log_file, 'a', encoding='utf-8') as f:
                    f.write(f"\nâœ… å‘½ä»¤æ‰§è¡ŒæˆåŠŸ\n")
            return True
            
    except Exception as e:
        print(f"\nâŒ æ‰§è¡Œå‘½ä»¤æ—¶å‡ºé”™: {e}")
        if log_file:
            with open(log_file, 'a', encoding='utf-8') as f:
                f.write(f"\nâŒ æ‰§è¡Œå‘½ä»¤æ—¶å‡ºé”™: {e}\n")
        return False


def main():
    curr_dir = os.path.dirname(os.path.abspath(__file__))
    default_base_dir = os.path.join(curr_dir, "../scripts_training2testing/examples")
    
    parser = argparse.ArgumentParser(description="æ‰¹é‡è¿è¡ŒThinkKTå®éªŒ")
    parser.add_argument("--base_dir", type=str, 
                       default=default_base_dir,
                       help="å·¥ä½œç›®å½•ï¼ˆåŒ…å«wandb_thinkkt_train.pyçš„ç›®å½•ï¼‰")
    parser.add_argument("--gpu_id", type=str, default="0", 
                       help="GPU IDï¼ˆå•ä¸ªï¼‰æˆ–GPUåˆ—è¡¨ï¼ˆé€—å·åˆ†éš”ï¼Œå¦‚'0,1,2,3'ï¼‰ã€‚å¦‚æœæä¾›å¤šä¸ªGPUï¼Œå°†è½®è¯¢åˆ†é…å®éªŒ")
    parser.add_argument("--fold", type=int, default=0, help="äº¤å‰éªŒè¯æŠ˜æ•°")
    parser.add_argument("--use_cot", type=int, default=0, 
                       help="æ˜¯å¦ä½¿ç”¨CoT (0=Baseline, 1=CoTç‰ˆæœ¬)")
    parser.add_argument("--cot_threshold", type=int, default=2,
                        help="CoTç”Ÿæˆçš„ç¨€ç–é˜ˆå€¼")
    parser.add_argument("--adaptive_strategy", type=str, default="rule", 
                        help="CoTç”Ÿæˆç­–ç•¥: 'rule' æˆ– 'learnable'")
    parser.add_argument("--pretrained_model_dir", type=str, default=None,
                        help="é¢„è®­ç»ƒæ¨¡å‹ç›®å½•(ç”¨äºlearnableæ¨¡å¼è·³è¿‡Step1)")
    parser.add_argument("--question_rep_type", type=str, default="visual", choices=["visual", "qid"],
                        help="é¢˜ç›®è¡¨å¾æ¥æº: 'visual' (ThinkKT) æˆ– 'qid' (CRKT)")
                        
    parser.add_argument("--num_epochs", type=int, default=200, help="è®­ç»ƒè½®æ•°")
    parser.add_argument("--batch_size", type=int, default=32, help="æ‰¹æ¬¡å¤§å°")
    parser.add_argument("--skip_training", action="store_true", 
                       help="è·³è¿‡è®­ç»ƒï¼Œåªè¿è¡Œæµ‹è¯•ï¼ˆç”¨äºé‡æ–°æµ‹è¯•å·²è®­ç»ƒçš„æ¨¡å‹ï¼‰")
    parser.add_argument("--skip_testing", action="store_true", 
                       help="è·³è¿‡æµ‹è¯•ï¼Œåªè¿è¡Œè®­ç»ƒ")
    parser.add_argument("--force", action="store_true",
                       help="å¼ºåˆ¶é‡æ–°è¿è¡Œæ‰€æœ‰å®éªŒï¼Œå³ä½¿å·²å®Œæˆï¼ˆå¿½ç•¥æ–­ç‚¹ç»­ä¼ ï¼‰")
    parser.add_argument("--experiment_range", type=str, default=None,
                       help="æŒ‡å®šè¦è¿è¡Œçš„å®éªŒç¼–å·ï¼ˆé€—å·åˆ†éš”ï¼‰ï¼Œå¦‚'1,5,9,13,17'ã€‚å¦‚æœä¸æŒ‡å®šï¼Œåˆ™è¿è¡Œæ‰€æœ‰å®éªŒ")
    
    args = parser.parse_args()
    
    # è§£æGPUåˆ—è¡¨
    if ',' in args.gpu_id:
        # å¤šä¸ªGPUï¼Œè§£æä¸ºåˆ—è¡¨
        gpu_list = [gpu.strip() for gpu in args.gpu_id.split(',') if gpu.strip()]
        print(f"[GPUåˆ†é…] ä½¿ç”¨å¤šGPUæ¨¡å¼: {gpu_list}")
    else:
        # å•ä¸ªGPUï¼Œè½¬æ¢ä¸ºåˆ—è¡¨
        gpu_list = [args.gpu_id]
        print(f"[GPUåˆ†é…] ä½¿ç”¨å•GPUæ¨¡å¼: {gpu_list}")
    
    # å®éªŒé…ç½®ï¼ˆæ³¨æ„ï¼šé…ç½®æ–‡ä»¶ä¸­ä½¿ç”¨çš„æ˜¯'nips_task34'ï¼Œä½†æ˜¾ç¤ºåç§°å¯ä»¥ç”¨'NIPS_task34'ï¼‰
    datasets = ["DBE_KT22", "XES3G5M", "nips_task34"]
    seq_model_types = ["lstm", "transformer"]
    num_layers_options = [1, 2, 3]
    
    # åˆ‡æ¢åˆ°å·¥ä½œç›®å½•
    original_dir = os.getcwd()
    os.chdir(args.base_dir)
    
    # åˆ›å»ºæ—¥å¿—ç›®å½•
    log_dir = "experiment_input_logs"
    os.makedirs(log_dir, exist_ok=True)
    
    # æ€»æ—¥å¿—æ–‡ä»¶ï¼ˆä½¿ç”¨ç»å¯¹è·¯å¾„ï¼Œé¿å…åˆ‡æ¢ç›®å½•åæ‰¾ä¸åˆ°ï¼‰
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    master_log = os.path.join(os.getcwd(), log_dir, f"all_experiments_{timestamp}.log")
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_experiments = 0
    completed_experiments = 0
    skipped_experiments = []  # è·³è¿‡çš„å·²å®Œæˆå®éªŒ
    failed_experiments = []
    
    datasets = ["DBE_KT22", "XES3G5M", "nips_task34"]
    question_rep_types = ["qid", "visual"]
    num_lstm_layers_options = [1, 2, 3]
    
    # ç”Ÿæˆæ‰€æœ‰å®éªŒç»„åˆ (3x2x3 = 18ä¸ª)
    experiments = []
    for dataset in datasets:
        for q_rep in question_rep_types:
            for num_layers in num_lstm_layers_options:
                experiments.append({
                    'dataset': dataset,
                    'question_rep_type': q_rep,
                    'seq_model_type': 'lstm',
                    'num_lstm_layers': num_layers,
                    'num_transformer_layers': None
                })
    
    total_experiments = len(experiments)
    
    # å¦‚æœæŒ‡å®šäº†experiment_rangeï¼Œç­›é€‰è¦è¿è¡Œçš„å®éªŒ
    experiment_indices_map = {}  # æ˜ å°„ï¼šå½“å‰ç´¢å¼• -> åŸå§‹å®éªŒç¼–å·ï¼ˆç”¨äºGPUåˆ†é…ï¼‰
    if args.experiment_range:
        try:
            # è§£æå®éªŒç¼–å·ï¼ˆä»1å¼€å§‹ï¼‰
            exp_indices = [int(x.strip()) for x in args.experiment_range.split(',')]
            # è½¬æ¢ä¸º0-basedç´¢å¼•ï¼Œå¹¶ç­›é€‰æœ‰æ•ˆçš„å®éªŒ
            valid_indices = [idx - 1 for idx in exp_indices if 1 <= idx <= total_experiments]
            if valid_indices:
                # ä¿å­˜æ˜ å°„å…³ç³»ï¼šå½“å‰ç´¢å¼• -> åŸå§‹å®éªŒç¼–å·
                filtered_experiments = []
                for new_idx, orig_idx in enumerate(valid_indices):
                    filtered_experiments.append(experiments[orig_idx])
                    experiment_indices_map[new_idx] = orig_idx + 1  # åŸå§‹ç¼–å·ï¼ˆä»1å¼€å§‹ï¼‰
                experiments = filtered_experiments
                print(f"[å®éªŒç­›é€‰] æ ¹æ® --experiment_range={args.experiment_range}ï¼Œç­›é€‰å‡º {len(experiments)} ä¸ªå®éªŒ")
                print(f"[å®éªŒç­›é€‰] åŸå§‹å®éªŒç¼–å·: {[i+1 for i in valid_indices]}")
            else:
                print(f"[è­¦å‘Š] æ²¡æœ‰æœ‰æ•ˆçš„å®éªŒç¼–å·ï¼Œå°†è¿è¡Œæ‰€æœ‰å®éªŒ")
        except ValueError as e:
            print(f"[è­¦å‘Š] è§£æ --experiment_range å¤±è´¥: {e}ï¼Œå°†è¿è¡Œæ‰€æœ‰å®éªŒ")
    else:
        # æ²¡æœ‰æŒ‡å®šèŒƒå›´ï¼Œæ‰€æœ‰å®éªŒéƒ½æŒ‰åŸå§‹ç¼–å·
        for i in range(len(experiments)):
            experiment_indices_map[i] = i + 1
    
    total_experiments = len(experiments)
    
    print("=" * 80)
    print("ThinkKT æ‰¹é‡å®éªŒè„šæœ¬")
    print("=" * 80)
    print(f"æ€»å®éªŒæ•°: {total_experiments}")
    if args.experiment_range:
        print(f"å®éªŒèŒƒå›´: {args.experiment_range}")
    print(f"æ•°æ®é›†: {datasets}")
    print(f"åºåˆ—æ¨¡å‹ç±»å‹: {seq_model_types}")
    print(f"å±‚æ•°é€‰é¡¹: {num_layers_options}")
    print(f"ä½¿ç”¨CoT: {args.use_cot}")
    print(f"GPUåˆ—è¡¨: {gpu_list}")
    print(f"Fold: {args.fold}")
    print(f"å¼ºåˆ¶é‡æ–°è¿è¡Œ: {args.force}")
    print(f"æ–­ç‚¹ç»­ä¼ : {'ç¦ç”¨' if args.force else 'å¯ç”¨'}")
    print(f"è®­ç»ƒè½®æ•°: {args.num_epochs}")
    print(f"æ‰¹æ¬¡å¤§å°: {args.batch_size}")
    print(f"æ—¥å¿—æ–‡ä»¶: {master_log}")
    print("=" * 80)
    
    with open(master_log, 'w', encoding='utf-8') as f:
        f.write(f"ThinkKT æ‰¹é‡å®éªŒæ—¥å¿—\n")
        f.write(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"æ€»å®éªŒæ•°: {total_experiments}\n")
        f.write("=" * 80 + "\n")
    
    # è¿è¡Œæ¯ä¸ªå®éªŒ
    # æ³¨æ„ï¼šidx æ˜¯å½“å‰å¾ªç¯ä¸­çš„ç´¢å¼•ï¼ˆä»1å¼€å§‹ï¼‰ï¼Œç”¨äºGPUè½®è¯¢åˆ†é…
    for idx, exp in enumerate(experiments, 1):
        print(f"\n{'='*80}")
        print(f"å®éªŒ {idx}/{total_experiments}")
        print(f"{'='*80}")
        
        # è½®è¯¢åˆ†é…GPUï¼ˆåŸºäºåŸå§‹å®éªŒç¼–å·ï¼Œè€Œä¸æ˜¯å½“å‰å¾ªç¯ç´¢å¼•ï¼‰
        original_exp_idx = experiment_indices_map.get(idx - 1, idx)  # è·å–åŸå§‹å®éªŒç¼–å·
        assigned_gpu = gpu_list[(original_exp_idx - 1) % len(gpu_list)]
        print(f"åˆ†é…GPU: cuda:{assigned_gpu} (å½“å‰å¾ªç¯ç´¢å¼•: {idx}, åŸå§‹å®éªŒç¼–å·: {original_exp_idx})")
        
        # æ„å»ºä¿å­˜ç›®å½•åç§°
        if args.use_cot:
             version_name = "cot_version_input"  # CoT ç‰ˆæœ¬ (Group 3)
        else:
             # Baseline ç‰ˆæœ¬ (Group 1 & 2)
             if exp['question_rep_type'] == 'qid':
                 version_name = "crkt_baseline"   # Group 1: CRKT å¤åˆ»
             else:
                 version_name = "visual_baseline" # Group 2: Visual åŸºçº¿

        base_save_dir = f"saved_model/{version_name}"
        
        exp_name = f"{exp['dataset']}_{exp['question_rep_type']}_{exp['seq_model_type']}_L{exp['num_lstm_layers']}"
        
        # save_dirä¼šè¢«è®­ç»ƒè„šæœ¬è‡ªåŠ¨ç”Ÿæˆå®Œæ•´è·¯å¾„ï¼Œè¿™é‡Œåªæä¾›åŸºç¡€ç›®å½•
        save_dir = base_save_dir
        
        print(f"æ•°æ®é›†: {exp['dataset']}")
        print(f"è¡¨å¾ç±»å‹: {exp['question_rep_type']}")
        print(f"åºåˆ—æ¨¡å‹: {exp['seq_model_type']}")
        print(f"å±‚æ•°: {exp['num_lstm_layers']}")
        print(f"ä¿å­˜ç›®å½•: {save_dir}")
        
        # å®éªŒæ—¥å¿—
        exp_log = os.path.join(log_dir, f"{exp_name}_{timestamp}.log")
        
        # æ–­ç‚¹ç»­ä¼ ï¼šæ£€æŸ¥å®éªŒæ˜¯å¦å·²å®Œæˆ
        base_save_dir_full = os.path.join(args.base_dir, f"saved_model/{version_name}")
        existing_model_dir = None
        is_completed = False
        
        if not args.force:
            # æŸ¥æ‰¾å·²å­˜åœ¨çš„æ¨¡å‹ç›®å½•
            if os.path.exists(base_save_dir_full):
                # æ„å»ºåŒ¹é…å…³é”®è¯ï¼ˆæ•°æ®é›†åç§° + åºåˆ—æ¨¡å‹ç±»å‹ï¼‰
                match_keywords = [exp['dataset'], exp['seq_model_type']]
                
                # æŸ¥æ‰¾åŒ¹é…çš„æ¨¡å‹ç›®å½•
                for item in os.listdir(base_save_dir_full):
                    item_path = os.path.join(base_save_dir_full, item)
                    if not os.path.isdir(item_path):
                        continue
                    
                    # æ£€æŸ¥ç›®å½•åæ˜¯å¦åŒ…å«æ‰€æœ‰å…³é”®è¯
                    if all(keyword in item for keyword in match_keywords):
                        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ¨¡å‹æ–‡ä»¶å’Œæµ‹è¯•ç»“æœï¼ˆåˆ¤æ–­æ˜¯å¦å®Œæˆï¼‰
                        model_file = None
                        test_file = None
                        config_file = None
                        
                        for f in os.listdir(item_path):
                            if f.endswith("_model.ckpt"):
                                model_file = os.path.join(item_path, f)
                            elif f == "config.json":
                                config_file = os.path.join(item_path, f)
                            # æ£€æŸ¥æµ‹è¯•ç»“æœæ–‡ä»¶ï¼ˆå¿…é¡»å­˜åœ¨æ‰è®¤ä¸ºå®éªŒå®Œæˆï¼‰
                            if f.endswith("_test_predictions.txt") or (f.startswith("predicting") and f.endswith(".log")):
                                test_file = os.path.join(item_path, f)
                        
                        # å®éªŒå®Œæˆçš„æ¡ä»¶ï¼šå¿…é¡»æœ‰æ¨¡å‹æ–‡ä»¶ã€é…ç½®æ–‡ä»¶ã€å’Œæµ‹è¯•ç»“æœæ–‡ä»¶
                        if (model_file and os.path.exists(model_file) and 
                            config_file and os.path.exists(config_file) and
                            test_file and os.path.exists(test_file)):
                            # è¿›ä¸€æ­¥éªŒè¯é…ç½®æ˜¯å¦åŒ¹é…ï¼ˆé€šè¿‡è¯»å–config.jsonï¼‰
                            try:
                                import json
                                with open(config_file, 'r') as f:
                                    saved_config = json.load(f)
                                    saved_params = saved_config.get('params', {})
                                    # æ£€æŸ¥å…³é”®å‚æ•°æ˜¯å¦åŒ¹é…ï¼ˆåŒ…æ‹¬å±‚æ•°ï¼‰
                                    saved_num_lstm_layers = saved_params.get('num_lstm_layers')
                                    saved_num_transformer_layers = saved_params.get('num_transformer_layers')
                                    exp_num_layers = exp['num_lstm_layers'] or exp['num_transformer_layers']
                                    
                                    # åŒ¹é…æ¡ä»¶ï¼šæ•°æ®é›†åç§°ã€åºåˆ—æ¨¡å‹ç±»å‹ã€å±‚æ•°éƒ½è¦åŒ¹é…
                                    if (saved_params.get('dataset_name') == exp['dataset'] and
                                        saved_params.get('seq_model_type') == exp['seq_model_type'] and
                                        saved_params.get('question_rep_type', 'visual') == exp['question_rep_type']):
                                        # æ£€æŸ¥å±‚æ•°æ˜¯å¦åŒ¹é…
                                        saved_num_layers = saved_num_lstm_layers or saved_num_transformer_layers
                                        if saved_num_layers == exp_num_layers:
                                            existing_model_dir = item_path
                                            is_completed = True
                                            break
                            except Exception as e:
                                # å¦‚æœè¯»å–é…ç½®å¤±è´¥ï¼Œä¸è®¤ä¸ºå·²å®Œæˆï¼ˆé¿å…è¯¯åˆ¤ï¼‰
                                pass
        
        if is_completed and not args.force:
            print(f"â­ï¸  å®éªŒå·²å®Œæˆï¼Œè·³è¿‡: {exp_name}")
            print(f"   æ¨¡å‹ç›®å½•: {existing_model_dir}")
            skipped_experiments.append(exp_name)
            completed_experiments += 1
            # è®°å½•åˆ°æ€»æ—¥å¿—
            with open(master_log, 'a', encoding='utf-8') as f:
                f.write(f"\nå®éªŒ {idx}/{total_experiments}: {exp_name}\n")
                f.write(f"çŠ¶æ€: å·²è·³è¿‡ï¼ˆå·²å®Œæˆï¼‰\n")
                f.write(f"æ¨¡å‹ç›®å½•: {existing_model_dir}\n")
                f.write(f"{'-'*80}\n")
            continue
        
        success = True
        actual_model_dir = None  # è®°å½•å®é™…æ¨¡å‹ä¿å­˜è·¯å¾„
        train_start_time = None  # è®°å½•è®­ç»ƒå¼€å§‹æ—¶é—´
        
        # 1. è®­ç»ƒ (Phase 1: Base Model)
        run_phase1 = not args.skip_training
        actual_model_dir = None
        
        # æ™ºèƒ½è·³è¿‡é€»è¾‘: å¦‚æœæ˜¯ Learnable æ¨¡å¼ï¼Œä¸”èƒ½æ‰¾åˆ°å·²å­˜åœ¨çš„åŸºçº¿æ¨¡å‹ï¼Œåˆ™è·³è¿‡ Phase 1
        if args.adaptive_strategy == 'learnable':
            # æœç´¢æœ€è¿‘çš„ä¸€ä¸ªå¯ç”¨æ¨¡å‹ç›®å½•
            if os.path.exists(save_dir):
                subdirs = [os.path.join(save_dir, d) for d in os.listdir(save_dir) if os.path.isdir(os.path.join(save_dir, d))]
                # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œæ‰¾æœ€æ–°çš„
                subdirs.sort(key=lambda x: os.path.getmtime(x), reverse=True)
                
                for d in subdirs:
                    if os.path.exists(os.path.join(d, "config.json")):  # æ£€æŸ¥é…ç½®æ˜¯å¦å­˜åœ¨ï¼Œè¿™æ˜¯æœ€åŸºæœ¬çš„
                        
                        # é¢å¤–æ£€æŸ¥: ç¡®ä¿è¿™ä¸ªæ¨¡å‹ä¸æ˜¯ RL è®­ç»ƒå‡ºæ¥çš„ (rl_model.pt) è€Œæ˜¯ Base æ¨¡å‹
                        # ä½†é€šå¸¸ wandb_train ç”Ÿæˆçš„ç›®å½•é‡Œä¼šæœ‰ config.json
                        print(f"ğŸ”„ [Auto-Skip] å‘ç°å·²æœ‰åŸºçº¿æ¨¡å‹ï¼Œè·³è¿‡ Phase 1ï¼Œç›´æ¥è¿›å…¥ RL è®­ç»ƒ: {d}")
                        actual_model_dir = d
                        run_phase1 = False
                        break
        
        # å¦‚æœç”¨æˆ·æ‰‹åŠ¨æŒ‡å®šäº†é¢„è®­ç»ƒæ¨¡å‹ (è¦†ç›–è‡ªåŠ¨æœç´¢)
        if args.pretrained_model_dir:
             print(f"ğŸ”„ [Manual-Skip] ä½¿ç”¨æŒ‡å®šåŸºçº¿æ¨¡å‹: {args.pretrained_model_dir}")
             actual_model_dir = args.pretrained_model_dir
             run_phase1 = False

        if run_phase1:
            train_start_time = datetime.now()  # è®°å½•è®­ç»ƒå¼€å§‹æ—¶é—´
            train_cmd = [
                "python", "wandb_thinkkt_train.py",
                "--dataset_name", exp['dataset'],
                "--fold", str(args.fold),
                "--seq_model_type", exp['seq_model_type'],
                "--use_cot", str(args.use_cot),
                "--use_visual", "1",
                "--save_dir", save_dir,
                "--num_epochs", str(args.num_epochs),
                "--batch_size", str(args.batch_size),
                "--gpu_id", assigned_gpu,  # ä½¿ç”¨è½®è¯¢åˆ†é…çš„GPU
                "--cot_threshold", str(args.cot_threshold),
                "--adaptive_strategy", args.adaptive_strategy,
                "--question_rep_type", exp['question_rep_type'] # ä½¿ç”¨å®éªŒç‰¹å®šçš„è¡¨å¾ç±»å‹
            ]
            
            if exp['num_transformer_layers'] is not None:
                train_cmd.extend(["--num_transformer_layers", str(exp['num_transformer_layers'])])
            
            if exp['num_lstm_layers'] is not None:
                train_cmd.extend(["--num_lstm_layers", str(exp['num_lstm_layers'])])
            
            success = run_command(
                train_cmd,
                f"è®­ç»ƒå®éªŒ: {exp_name}",
                log_file=exp_log
            )
            
            if not success:
                print(f"âŒ è®­ç»ƒå¤±è´¥: {exp_name}")
                failed_experiments.append(exp_name)
                continue
            
            # è®­ç»ƒå®Œæˆåï¼Œä»æ—¥å¿—ä¸­æå–å®é™…ä¿å­˜è·¯å¾„
            # æˆ‘ä»¬éœ€è¦è§£ææ—¥å¿—æ–‡ä»¶æ¥æ‰¾åˆ° "æœ€ä½³æ¨¡å‹ä¿å­˜åœ¨: ..." çš„è¡Œï¼Œæˆ–è€…ç›´æ¥æ ¹æ®è§„åˆ™æ¨æ–­
            # ä¸ºäº†ç®€å•ï¼Œæˆ‘ä»¬è®© wandb_thinkkt_train.py æœ€åæ‰“å°ä¸€è¡Œç‰¹æ®Šæ ‡è®°ï¼Œä¾‹å¦‚ [RESULT_DIR]: /path/to/dir
            # æˆ–è€…æˆ‘ä»¬ç›´æ¥æ ¹æ® save_dir å’Œ exp_name çŒœæµ‹
            
            # è¿™é‡Œå°è¯•ç®€å•æ¨æ–­: save_dir/cot_version_input/dataset_model_layer
            # ä½† wandb_train.py ä¼šæ·»åŠ  uuid, æ‰€ä»¥æœ€å¥½æ˜¯ä»æ—¥å¿—è¯»
            if args.adaptive_strategy == 'learnable':
                # è¯»å–æ—¥å¿—å¯»æ‰¾è·¯å¾„
                if os.path.exists(exp_log):
                    with open(exp_log, 'r') as f:
                        for line in f:
                            if "æ¨¡å‹ç›®å½•:" in line: # wandb_train.py éœ€è¦æ‰“å°è¿™ä¸ª
                                actual_model_dir = line.split(":")[-1].strip()
                                break
                                
                if not actual_model_dir:
                    print(f"âš ï¸ æ— æ³•æ‰¾åˆ°é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„ï¼Œè·³è¿‡RLè®­ç»ƒ")
                else:
                    print(f"ğŸ”„ æ£€æµ‹åˆ° learnable ç­–ç•¥ï¼Œå¼€å§‹ RL è®­ç»ƒ...")
                    print(f"   åŸºç¡€æ¨¡å‹è·¯å¾„: {actual_model_dir}")
                    
                    rl_log = os.path.join(save_dir, f"rl_train_{exp_name}.log")
                    rl_cmd = [
                        "python", "scripts/train_rl.py",
                        "--dataset_name", exp['dataset'],
                        "--kt_model_path", actual_model_dir,
                        "--fold", str(args.fold),
                        "--gpu_id", assigned_gpu,
                        "--lambda_cost", "0.1" # é»˜è®¤å€¼
                    ]
                    
                    success_rl = run_command(rl_cmd, f"RLè®­ç»ƒ: {exp_name}", log_file=rl_log)
                    if success_rl:
                        print(f"âœ… RLè®­ç»ƒå®Œæˆ")
                    else:
                        print(f"âŒ RLè®­ç»ƒå¤±è´¥")
            
            if os.path.exists(exp_log):
                with open(exp_log, 'r', encoding='utf-8') as f:
                    log_lines = f.readlines()
                    # ä»åå¾€å‰æŸ¥æ‰¾ï¼ˆè·¯å¾„é€šå¸¸åœ¨æœ€åï¼‰
                    for line in reversed(log_lines):
                        # æŸ¥æ‰¾åŒ…å«æ¨¡å‹ä¿å­˜è·¯å¾„çš„è¡Œ
                        if 'saved_model' in line:
                            # å°è¯•æå–è·¯å¾„
                            for word in line.split():
                                if 'saved_model' in word and exp['dataset'] in word:
                                    potential = word.strip("'\"(),[]\\n:")
                                    # æ„å»ºå®Œæ•´è·¯å¾„
                                    if not os.path.isabs(potential):
                                        potential = os.path.join(args.base_dir, potential)
                                    if os.path.exists(potential) and os.path.isdir(potential):
                                        actual_model_dir = potential
                                        break
                            if actual_model_dir:
                                break
        
        # 2. æµ‹è¯•ï¼ˆéœ€è¦æ‰¾åˆ°å®é™…ä¿å­˜çš„æ¨¡å‹è·¯å¾„ï¼‰
        if not args.skip_testing and success:
            # ç­‰å¾…ä¸€ä¸‹ï¼Œç¡®ä¿æ¨¡å‹æ–‡ä»¶å·²ä¿å­˜
            import time
            time.sleep(3)
            
            # æŸ¥æ‰¾æ¨¡å‹ä¿å­˜è·¯å¾„
            # å®é™…è·¯å¾„æ ¼å¼ï¼šsaved_model/{version_name}/{dataset}_{fold}_{lr}_{batch}_{model}_{emb}_{...}
            base_save_dir_full = os.path.join(args.base_dir, f"saved_model/{version_name}")
            model_save_dir = None
            
            # æ–¹æ³•1: ä½¿ç”¨è®­ç»ƒåè®°å½•çš„è·¯å¾„ï¼ˆå¦‚æœå·²æå–ï¼‰
            if actual_model_dir and os.path.exists(actual_model_dir):
                model_save_dir = actual_model_dir
            
            # æ–¹æ³•0: å¦‚æœå·²æœ‰å·²å®Œæˆçš„æ¨¡å‹ç›®å½•ï¼ˆæ–­ç‚¹ç»­ä¼ çš„æƒ…å†µï¼‰ï¼Œä¼˜å…ˆä½¿ç”¨
            if model_save_dir is None and existing_model_dir and os.path.exists(existing_model_dir):
                model_save_dir = existing_model_dir
            
            # æ–¹æ³•2: åœ¨base_save_dirä¸­æŸ¥æ‰¾æœ€è¿‘åˆ›å»ºçš„ã€åŒ…å«æ•°æ®é›†åç§°çš„ç›®å½•
            if model_save_dir is None and os.path.exists(base_save_dir_full):
                matching_dirs = []
                for item in os.listdir(base_save_dir_full):
                    item_path = os.path.join(base_save_dir_full, item)
                    if os.path.isdir(item_path):
                        # æ£€æŸ¥æ˜¯å¦åŒ¹é…ï¼šåŒ…å«æ•°æ®é›†åç§°
                        if exp['dataset'] in item:
                            # æ£€æŸ¥åˆ›å»ºæ—¶é—´ï¼ˆåº”è¯¥åœ¨è®­ç»ƒå¼€å§‹ä¹‹åï¼‰
                            mtime = os.path.getmtime(item_path)
                            if train_start_time is None or mtime >= train_start_time.timestamp() - 60:  # å…è®¸1åˆ†é’Ÿçš„è¯¯å·®
                                matching_dirs.append((item_path, mtime))
                
                if matching_dirs:
                    # ä½¿ç”¨æœ€æ–°çš„ç›®å½•
                    matching_dirs.sort(key=lambda x: x[1], reverse=True)
                    model_save_dir = matching_dirs[0][0]
            
            # æ–¹æ³•3: ä»è®­ç»ƒæ—¥å¿—ä¸­æå–è·¯å¾„
            if model_save_dir is None and os.path.exists(exp_log):
                with open(exp_log, 'r', encoding='utf-8') as f:
                    log_lines = f.readlines()
                    for line in reversed(log_lines):  # ä»åå¾€å‰æŸ¥æ‰¾ï¼ˆé€šå¸¸è·¯å¾„åœ¨æœ€åï¼‰
                        if 'saved_model' in line or 'save_dir' in line.lower():
                            # å°è¯•æå–è·¯å¾„
                            for word in line.split():
                                if 'saved_model' in word:
                                    potential = word.strip("'\"(),[]\\n")
                                    if not os.path.isabs(potential):
                                        potential = os.path.join(args.base_dir, potential)
                                    if os.path.exists(potential) and os.path.isdir(potential):
                                        model_save_dir = potential
                                        break
                            if model_save_dir:
                                break
            
            if model_save_dir and os.path.exists(model_save_dir):
                # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                model_file = None
                for f in os.listdir(model_save_dir):
                    if f.endswith("_model.ckpt"):
                        model_file = os.path.join(model_save_dir, f)
                        break
                
                if model_file and os.path.exists(model_file):
                    test_cmd = [
                        "python", "wandb_predict.py",
                        "--save_dir", model_save_dir,
                        "--bz", str(args.batch_size),
                        "--gpu_id", assigned_gpu  # ä½¿ç”¨ä¸è®­ç»ƒç›¸åŒçš„GPU
                    ]
                    
                    test_success = run_command(
                        test_cmd,
                        f"æµ‹è¯•å®éªŒ: {exp_name}",
                        log_file=exp_log
                    )
                    
                    if not test_success:
                        print(f"âš ï¸ æµ‹è¯•å¤±è´¥: {exp_name}")
                else:
                    print(f"âš ï¸ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡æµ‹è¯•")
                    print(f"   æŸ¥æ‰¾ç›®å½•: {model_save_dir}")
            else:
                print(f"âš ï¸ æ— æ³•æ‰¾åˆ°æ¨¡å‹ä¿å­˜ç›®å½•ï¼Œè·³è¿‡æµ‹è¯•")
                print(f"   å°è¯•æŸ¥æ‰¾: {base_save_dir_full}")
        
        if success:
            completed_experiments += 1
            print(f"âœ… å®éªŒå®Œæˆ: {exp_name}")
        else:
            print(f"âŒ å®éªŒå¤±è´¥: {exp_name}")
        
        # è®°å½•åˆ°æ€»æ—¥å¿—
        with open(master_log, 'a', encoding='utf-8') as f:
            f.write(f"\nå®éªŒ {idx}/{total_experiments}: {exp_name}\n")
            f.write(f"åˆ†é…GPU: cuda:{assigned_gpu}\n")
            f.write(f"çŠ¶æ€: {'æˆåŠŸ' if success else 'å¤±è´¥'}\n")
            f.write(f"{'-'*80}\n")
    
    # æ¢å¤åŸå§‹ç›®å½•
    os.chdir(original_dir)
    
    # æ‰“å°æ€»ç»“
    print("\n" + "=" * 80)
    print("å®éªŒæ€»ç»“")
    print("=" * 80)
    print(f"æ€»å®éªŒæ•°: {total_experiments}")
    print(f"å®Œæˆå®éªŒ: {completed_experiments}")
    print(f"è·³è¿‡å®éªŒ: {len(skipped_experiments)}")
    print(f"å¤±è´¥å®éªŒ: {len(failed_experiments)}")
    if skipped_experiments:
        print(f"\nè·³è¿‡çš„å®éªŒï¼ˆå·²å®Œæˆï¼‰:")
        for exp in skipped_experiments:
            print(f"  - {exp}")
    if failed_experiments:
        print(f"\nå¤±è´¥çš„å®éªŒ:")
        for exp in failed_experiments:
            print(f"  - {exp}")
    print(f"\næ€»æ—¥å¿—æ–‡ä»¶: {master_log}")
    print("=" * 80)
    
    # ä¿å­˜æ€»ç»“åˆ°æ—¥å¿—
    with open(master_log, 'a', encoding='utf-8') as f:
        f.write(f"\n{'='*80}\n")
        f.write(f"å®éªŒæ€»ç»“\n")
        f.write(f"{'='*80}\n")
        f.write(f"ç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"æ€»å®éªŒæ•°: {total_experiments}\n")
        f.write(f"å®Œæˆå®éªŒ: {completed_experiments}\n")
        f.write(f"è·³è¿‡å®éªŒ: {len(skipped_experiments)}\n")
        f.write(f"å¤±è´¥å®éªŒ: {len(failed_experiments)}\n")
        if skipped_experiments:
            f.write(f"è·³è¿‡çš„å®éªŒï¼ˆå·²å®Œæˆï¼‰:\n")
            for exp in skipped_experiments:
                f.write(f"  - {exp}\n")
        if failed_experiments:
            f.write(f"å¤±è´¥çš„å®éªŒ:\n")
            for exp in failed_experiments:
                f.write(f"  - {exp}\n")


if __name__ == "__main__":
    main()

