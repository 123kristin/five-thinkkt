# ThinkKT 完整流程图

## 数据流程图

```
┌─────────────────────────────────────────────────────────────────────────┐
│                           输入数据 (Input Data)                           │
│  qseqs: (batch, seq_len-1) 问题ID序列                                    │
│  rseqs: (batch, seq_len-1) 答题结果序列 (历史)                           │
│  shft_rseqs: (batch, seq_len-1) 答题结果序列 (标签)                      │
│  cseqs: (batch, seq_len-1, max_concepts) 知识点序列 (可选)                │
└─────────────────────────────────────────────────────────────────────────┘
                                      │
                                      ▼
┌─────────────────────────────────────────────────────────────────────────┐
│                   模块一：多模态题目理解器                                │
│                  (Visual-Language Encoder)                               │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                           │
│  For each question ID q_i in qseqs:                                      │
│                                                                           │
│    ┌──────────────────────────────┐                                      │
│    │  1. 查找图片路径              │                                      │
│    │     img_path = img_path_dict[q_i]                                   │
│    └──────────────┬───────────────┘                                      │
│                   │                                                       │
│                   ▼                                                       │
│    ┌──────────────────────────────┐                                      │
│    │  2. 加载并处理图片            │                                      │
│    │     Image.open(img_path)                                            │
│    └──────────────┬───────────────┘                                      │
│                   │                                                       │
│                   ▼                                                       │
│    ┌──────────────────────────────┐                                      │
│    │  3. Qwen2.5-VL 提取特征      │                                      │
│    │     vision_model(image) → hidden_states                             │
│    └──────────────┬───────────────┘                                      │
│                   │                                                       │
│                   ▼                                                       │
│    ┌──────────────────────────────┐                                      │
│    │  4. 特征投影                  │                                      │
│    │     feature_proj(hidden_state) → v_t (1024维)                      │
│    └──────────────┬───────────────┘                                      │
│                   │                                                       │
│                   ▼                                                       │
│    ┌──────────────────────────────┐                                      │
│    │  5. 预测知识点分布            │                                      │
│    │     kc_classifier(v_t) → k_t (num_c维, 0-1概率)                    │
│    └──────────────┬───────────────┘                                      │
│                                                                           │
└───────────────────────────────┬───────────────────────────────────────────┘
                                │
                ┌───────────────┴───────────────┐
                │  v_t: (batch, seq_len, 1024)  │
                │  k_t: (batch, seq_len, num_c) │
                └───────────────┬───────────────┘
                                │
                                ▼
┌─────────────────────────────────────────────────────────────────────────┐
│                   模块二：知识推理链生成器                                │
│                    (CoT Generator) - 可选                                 │
├─────────────────────────────────────────────────────────────────────────┤
│  If use_cot == True:                                                     │
│                                                                           │
│    For each position (b, s) in sequence:                                 │
│                                                                           │
│    ┌──────────────────────────────┐                                      │
│    │  1. 构建历史交互              │                                      │
│    │     history_qids = qseqs[b, :s]                                     │
│    │     history_rs = rseqs[b, :s]                                       │
│    │     current_qid = qseqs[b, s]                                       │
│    └──────────────┬───────────────┘                                      │
│                   │                                                       │
│                   ▼                                                       │
│    ┌──────────────────────────────┐                                      │
│    │  2. 构建Prompt                │                                      │
│    │     build_cot_prompt(...) → prompt文本                              │
│    └──────────────┬───────────────┘                                      │
│                   │                                                       │
│                   ▼                                                       │
│    ┌──────────────────────────────┐                                      │
│    │  3. MLLM生成CoT文本           │                                      │
│    │     mllm_model.generate(image, prompt) → cot_text                   │
│    │     例如: "学生已掌握三角形面积公式，当前题考查勾股定理..."        │
│    └──────────────┬───────────────┘                                      │
│                   │                                                       │
│                   ▼                                                       │
│    ┌──────────────────────────────┐                                      │
│    │  4. 文本编码                  │                                      │
│    │     text_encoder(cot_text) → r_t (384维)                           │
│    └──────────────┬───────────────┘                                      │
│                                                                           │
│  Else:                                                                   │
│    r_t = None                                                            │
│                                                                           │
└───────────────────────────────┬───────────────────────────────────────────┘
                                │
                ┌───────────────┴───────────────┐
                │  r_t: (batch, seq_len, 384)   │
                │   或 None                      │
                └───────────────┬───────────────┘
                                │
                                ▼
┌─────────────────────────────────────────────────────────────────────────┐
│                   模块三：知识状态追踪器                                  │
│                      (ThinkKTNet)                                        │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                           │
│  ┌──────────────────────────────────────────────────────┐               │
│  │  步骤1: 特征融合                                       │               │
│  │                                                        │               │
│  │    a_t = answer_emb(rseqs)  # 答题结果嵌入 (256维)    │               │
│  │                                                        │               │
│  │    If use_cot and r_t is not None:                    │               │
│  │      z = Concat([v_t, a_t, r_t, k_t])                │               │
│  │    Else:                                               │               │
│  │      z = Concat([v_t, a_t, k_t])                      │               │
│  │                                                        │               │
│  │    z = fusion_layer(z)  # → (batch, seq_len, 512)    │               │
│  └────────────────────────┬──────────────────────────────┘               │
│                           │                                               │
│                           ▼                                               │
│  ┌──────────────────────────────────────────────────────┐               │
│  │  步骤2: 序列建模                                       │               │
│  │                                                        │               │
│  │    If seq_model_type == "transformer":                │               │
│  │      h_t = TransformerEncoder(z)                      │               │
│  │    Else if seq_model_type == "lstm":                  │               │
│  │      h_t, (h_n, c_n) = LSTM(z)                        │               │
│  │                                                        │               │
│  │    h_t: (batch, seq_len, 512) 知识状态序列            │               │
│  └────────────────────────┬──────────────────────────────┘               │
│                           │                                               │
│                           ▼                                               │
│  ┌──────────────────────────────────────────────────────┐               │
│  │  步骤3: 预测                                          │               │
│  │                                                        │               │
│  │    y_pred = predictor(h_t)  # → (batch, seq_len-1)   │               │
│  │    # 答对概率预测                                      │               │
│  │                                                        │               │
│  │    kc_mastery = kc_mastery_head(h_t)                  │               │
│  │    # → (batch, seq_len, num_c) 知识点掌握度          │               │
│  └────────────────────────┬──────────────────────────────┘               │
│                                                                           │
└───────────────────────────────┬───────────────────────────────────────────┘
                                │
                                ▼
┌─────────────────────────────────────────────────────────────────────────┐
│                           输出 (Output)                                   │
│                                                                           │
│  y_pred: (batch, seq_len-1) 预测答对概率 [0, 1]                         │
│  loss: 二元交叉熵损失 BCE(y_pred, shft_rseqs)                           │
│                                                                           │
│  可选输出:                                                                │
│  - kc_mastery: (batch, seq_len, num_c) 知识点掌握度                     │
│  - cot_text: 生成的思维链文本（如果启用CoT）                             │
└─────────────────────────────────────────────────────────────────────────┘
```

## 训练流程（三阶段）

```
┌─────────────────────────────────────────────────────────────────────────┐
│                        阶段1: 基础训练 (Baseline)                         │
├─────────────────────────────────────────────────────────────────────────┤
│  配置: use_cot=0, use_visual=1                                           │
│                                                                           │
│  输入 → VisualEncoder → ThinkKTNet → 预测                                │
│                                                                           │
│  损失: BCE(y_pred, y_true)                                               │
│  优化: 视觉编码器 + 知识状态追踪器                                        │
└─────────────────────────────────────────────────────────────────────────┘
                                      │
                                      ▼
┌─────────────────────────────────────────────────────────────────────────┐
│                    阶段2: CoT增强训练 (CoT Version)                       │
├─────────────────────────────────────────────────────────────────────────┤
│  配置: use_cot=1, use_visual=1                                           │
│                                                                           │
│  输入 → VisualEncoder → CoTGenerator → ThinkKTNet → 预测                 │
│                     ↓                                                    │
│                 生成CoT文本                                               │
│                                                                           │
│  损失: BCE(y_pred, y_true)                                               │
│  优化: 视觉编码器 + CoT生成器 + 知识状态追踪器                            │
└─────────────────────────────────────────────────────────────────────────┘
                                      │
                                      ▼
┌─────────────────────────────────────────────────────────────────────────┐
│                   阶段3: RL优化训练 (Full Version)                        │
├─────────────────────────────────────────────────────────────────────────┤
│  冻结: ThinkKTNet (KT模型)                                               │
│  优化: CoTGenerator (RL优化)                                             │
│                                                                           │
│  输入 → CoTGenerator → ThinkKTNet (冻结) → 预测                          │
│          ↓                    ↓                                          │
│      生成CoT              计算奖励                                        │
│          ↓                    ↓                                          │
│      策略梯度 ←──────── 多目标奖励                                        │
│      更新CoT                                                              │
│                                                                           │
│  奖励函数:                                                                │
│    R = λ₁·R_pred + λ₂·R_cons + λ₃·R_kc + λ₄·R_len                       │
│                                                                           │
│  损失: REINFORCE策略梯度                                                  │
└─────────────────────────────────────────────────────────────────────────┘
```

## 数据维度变化

```
输入:
  qseqs:     (batch, seq_len-1)          问题ID
  rseqs:     (batch, seq_len-1)          答题结果 (0/1)
  shft_rseqs: (batch, seq_len-1)         标签 (0/1)
  
经过 VisualEncoder:
  v_t:       (batch, seq_len-1, 1024)    题目特征
  k_t:       (batch, seq_len-1, num_c)   知识点分布

经过 CoTGenerator (可选):
  r_t:       (batch, seq_len-1, 384)     CoT嵌入
  
经过 ThinkKTNet:
  z:         (batch, seq_len-1, d_input) 融合特征
             d_input = 1024 + 256 + 384 + num_c (如果使用CoT)
             或 1024 + 256 + num_c (如果不使用CoT)
             
  h_t:       (batch, seq_len-1, 512)     知识状态
  
输出:
  y_pred:    (batch, seq_len-1)          答对概率 [0,1]
  kc_mastery: (batch, seq_len-1, num_c)  知识点掌握度 [0,1]
```

## 模块交互图

```
                    ┌──────────────┐
                    │  输入数据     │
                    └──────┬───────┘
                           │
        ┌──────────────────┼──────────────────┐
        │                  │                  │
        ▼                  ▼                  ▼
  ┌──────────┐      ┌──────────┐      ┌──────────┐
  │ Visual   │      │   CoT    │      │ 答题历史  │
  │ Encoder  │      │Generator │      │  rseqs   │
  └────┬─────┘      └────┬─────┘      └────┬─────┘
       │                 │                  │
       │ v_t, k_t        │ r_t              │ a_t
       │                 │                  │
       └─────────────────┼──────────────────┘
                         │
                         ▼
                  ┌──────────────┐
                  │  Feature     │
                  │  Fusion      │
                  └──────┬───────┘
                         │
                         ▼
                  ┌──────────────┐
                  │ Transformer  │
                  │   or LSTM    │
                  └──────┬───────┘
                         │
                         ▼
                  ┌──────────────┐
                  │  Predictor   │
                  └──────┬───────┘
                         │
                         ▼
                   预测结果 y_pred
```

